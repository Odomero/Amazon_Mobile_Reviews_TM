---
title: "Topic Modeling"
author: "Joao Macosso, Odomero, Koki"
date: "2023-02-06"
output: 
  html_document:
    theme: spacelab
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
options(warn=-1)
suppressWarnings(expression)
knitr::opts_chunk$set(echo = TRUE)
```

# Required Libraries

```{r}
library(readr)
library(dplyr)
library(pander)
library(tm)
library(SnowballC)
library(textstem)
library(magrittr)
library(tidytext)
library(tm)
library(topicmodels)
library(tidyverse)
library(scales)
library(caret)
```

## Import some user define functions

```{r}
source("src/SupportFunctions.R")
```

#NLP

### Read Required Datasets

```{r warning=FALSE}
phone_review_data <- read_csv("data/mobile-phones-20191226-reviews.csv")
brands <- read_csv("data/mobile-phones-20191226-items.csv")

```

Merge the dataset to include brands

```{r}
phone_review_data <- phone_review_data %>% left_join(brands %>% select(asin,brand),
                                by = "asin")
# We keep only the rows with available brand
phone_review_data <- phone_review_data %>% filter(!is.na(brand))
```
The file is too large, it contains more than 30K reviews, rendering takes too much of the memory, Therefore only the 1/4 of it is will be used
```{r}
set.seed(10)
selection <- createDataPartition(phone_review_data$rating, p=0.05, list=FALSE)
phone_review_data <- phone_review_data[selection,]

```

### Clean the text

```{r}
docs <- Corpus(VectorSource(phone_review_data$body))

toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")

# remove unnecessary spaces
docs <- tm_map(docs, stripWhitespace)

# remove unnecessary punctuation
docs <- tm_map(docs, removePunctuation)

# remove unnecessary numbers
docs <- tm_map(docs, removeNumbers)

# change to lowercase
docs <- tm_map(docs, content_transformer(tolower))

# remove English stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
```

### Term frequency matrix

```{r}
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
```

# Topic Modeling

```{r}
data("stop_words")
phone_review_data$body <- gsub("\\'", "", phone_review_data$body) # Removes Apostrophes white spaces
phone_review_data$body  <-  gsub('[[:punct:] ]+',' ',phone_review_data$body) # Remove Punctuation 
phone_review_data$body <- gsub('[[:digit:]]+', '', phone_review_data$body) # Remove numbers
phone_review_data$body <- as.character(phone_review_data$body)
```

## Most impotant words in each rating

```{r}
# get the count of each word in review in eac h rating
words <- phone_review_data %>%
  unnest_tokens(word, body) %>%
  anti_join(stop_words) %>%
  count(rating, word) %>% 
  ungroup() 

# get the number of words per text
total_words <- words %>% 
  group_by(rating) %>% 
  summarize(total = sum(n))

# combine the two dataframes we just made
words <- left_join(words, total_words)

# get the tf_idf & order the words by degree of relevence
tf_idf <- words %>%
  bind_tf_idf(word, rating, n) %>%
  select(-total) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))
```


```{r}

tf_idf <- words %>%
    bind_tf_idf(word, rating, n) %>%
    select(-total) %>%
    arrange(desc(tf_idf)) %>%
    mutate(word = factor(word, levels = rev(unique(word))))


tf_idf %>% group_by(rating) %>% 
      top_n(7,tf_idf) %>% 
      ungroup %>%
      ggplot(aes(word, tf_idf, fill = as.factor(rating))) +
      geom_col(show.legend = FALSE) + 
      labs(title = "Top words in each Rating", x = "Words", y = "Frequency") + 
      scale_y_continuous(n.breaks = 3, labels = scales::percent) +
      facet_wrap(rating~., scales = "free")+
      coord_flip()
```

## Most impotant words in each brand

```{r}
# get the count of each word in review in eac h rating
words_brand <- phone_review_data %>%
  unnest_tokens(word, body) %>%
  anti_join(stop_words) %>%
  count(brand, word) %>% 
  ungroup() 

# get the number of words per text
total_words <- words_brand %>% 
  group_by(brand) %>% 
  summarize(total = sum(n))

# combine the two dataframes we just made
words_brand <- left_join(words_brand, total_words)

# get the tf_idf & order the words by degree of relevence
tf_idf <- words_brand %>%
  bind_tf_idf(word, brand, n) %>%
  select(-total) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))


tf_idf_brand <- words_brand %>%
    bind_tf_idf(word, brand, n) %>%
    select(-total) %>%
    arrange(desc(tf_idf)) %>%
    mutate(word = factor(word, levels = rev(unique(word))))


tf_idf_brand %>% group_by(brand) %>% 
      top_n(7,tf_idf) %>% 
      ungroup %>%
      ggplot(aes(word, tf_idf, fill = as.factor(brand))) +
      geom_col(show.legend = FALSE) + 
      labs(title = "Top words in each Mobile phone brand Review", x = "Words", y = "Frequency") + 
      scale_y_continuous(n.breaks = 3, labels = scales::percent) +
      facet_wrap(brand~., scales = "free")+
      coord_flip()
```

```{r}
#top_terms_by_topic_tfidf(text_df = phone_review_data, # dataframe
#                         text_column = body, # column with text
#                         group_column = rating, # column with topic label
#                         plot = F) # return a plot
#
```

